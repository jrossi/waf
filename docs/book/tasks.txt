
== Task processing

This chapter provides a description of the task classes which are used during the build phase.

=== Execution overview

==== Build groups

the build is structured into groups

==== Task states

cache, status, signature

==== Producer-consumer system

prodcons diagram



=== Build order constraints

==== set_run_after

TODO

==== computed constraints

===== after/before

TODO

===== ext_in/ext_out

TODO

===== files inputs/outputs

TODO

==== soft order constraints

diagrams, ...




=== Dependencies

==== Task signatures

TODO

==== Explicit dependencies

TODO

==== Implicit dependencies and scanners

TODO

==== Variables

TODO




=== Task creation and execution

Creating all tasks by hand is a tedious process that the task generators may automate. Before starting the build, Waf asks each task generator to produce the corresponding tasks. If Waf is launched from a sub folder inside the source directory, it will try to avoid the creation of the tasks that are not relevant for that particular sub folder (optimization).

Here are a few motives for using the task generators to create the tasks instead of creating them manually:

. Lazy creation: building only a part of the project is a common scenario
. Filesystem access: the filesystem requirements such as new folders will be created ahead of time
. Concurrency issues: tasks are executed in parallel and may lead to complex bugs if initialized improperly

A summary can be found on the following diagram:

image::task_execution{PIC}["Flowchart model"{backend@docbook:,width=370:},align="center"]

=== Task execution

Executing a task consists in calling the method 'run' on that task, and setting the task execution state.
The following diagram is a summary of the process:

image::task_run{PIC}["Task execution"{backend@docbook:,width=250:},align="center"]

The method 'post_run' can be used to check if the files have been produced, it must throw an OSError if the task has not completed properly.

=== Task execution in parallel

Tasks may be executed in parallel to take advantage of the hardware (multi-core) or the environment (distributed builds). By default Waf does not execute immediately the tasks that are ready. Instead, tasks are added to a queue which is consumed by threads. Waf detects the number of installed processors. For uni-processor only one task is executed at a time, for dual-processors two tasks are executed at a time, and so on. To disable task parallelization, use the option '-j1'. To enhance parallelization, use the option '-j' with the amount of consumers:

[source,shishell]
------------------
$ waf -j3
------------------

By default, Waf does not allow consumer threads to access the tasks directly:

. There is little need for parallelizing the computation of the next task to execute, choosing the next task is fast enough
. The thread issues are limited to a very small section of the code
. The producer-consumer scheme prevents 'busy waiting' for the next task
. A simple global error handler can be used for processing the errors and to decide to stop the build

The following illustrates the relationship producer-consumer performed for the builds:

image::parallel{PIC}["Parallel execution"{backend@docbook:,width=500:},align="center"]



=== Task execution order

Running tasks in parallel is a simple problem, but in practice it is more complicated:
. Dependencies can be discovered during the build (dynamic task creation)
. New ordering constraints can be discovered after files are compiled
. The amount of tasks and ordering constraints (graph size) can be huge and performance may be a problem

To make the problem more simple, it is divided by the different concerns, and the ordering constraints can be given on three different levels:

. groups of tasks may run only after another group of tasks has finished to run, this represents a strict sequential order between groups of tasks, for example a compiler is produced and used to compile the tasks in the next group
. task types to indicate the instance will run after other task type instances, for example linking object files may only occur after compiling the source files
. specific constraints for task instances that can only run after a few other task instances


==== Task groups

In some circumstances it is necessary to build a compiler and all its dependencies before using it for executing some other tasks (bootstrapping). The following demonstrates how declare groups of tasks to be executed after other groups of tasks:

[source,python]
---------------
def build(bld):
	bld(features='cc cprogram', source='main.c', target='mycompiler')
	bld.add_group()
	bld(features='cc cprogram', source='user.c', target='someotherapp')
---------------

The effect of task groups when running tasks in parallel is illustrated by the following diagram. Three groups of tasks have been added, and the execution of the next group only starts when the execution of the tasks in the previous group is complete.

image::output-ADDGROUP{PIC}["Task groups"{backend@docbook:,width=350:},align="center"]

It is possible to create groups at any point in the scripts, and to add the task generators to any group previously created. Adding groups for specific folders or scripts enables a behaviour similar to projects organized in recursive Makefiles.

[source,python]
---------------
def build(bld):

	bld.add_group('test1')
	bld.add_group('test2')
	bld.add_group('test3')
	bld.add_group('test4')

	print('adding task generators')

	bld.set_group('test3')
	bld(features='cxx cprogram', source='main3.c', target='g3')

	bld.set_group('test1')
	bld(features='cxx cprogram', source='main1.c', target='g1')

	bld.set_group('test2')
	obj2 = bld(features='cxx cprogram', source='main2.c', target='g2')

	bld.set_group('test4')
	obj2.clone('debug')
---------------

Because task groups prevent parallelization, they reduce performance. On the other hand, they make projects more structured and improve the maintainance.


==== Precedence constraints

The attributes 'before' and 'after' are used to declare ordering constraints between tasks:

[source,python]
---------------
from waflib import Task
class task_test_a(Task.TaskBase):
	before = 'task_test_b'
class task_test_b(Task.TaskBase):
	after = 'task_test_a'
---------------

Another way to declare precedence constraints is to declare a file extension production, for example:

[source,python]
---------------
from waflib import Task
class task_test_a(Task.TaskBase):
	ext_in = '.c'
class task_test_b(Task.TaskBase):
	ext_out = '.c'
---------------

The 'extensions' ext_in and ext_out have to match to add a valid precedence constraint, but they are only symbols in this context. They do not mean the tasks actually have to produce files of that type.

==== Precedence constraints on task instances

The method 'set_run_after' is used to declare ordering constraints between tasks:

[source,python]
---------------
task1.set_run_after(task2)
---------------

unlike the previous constraints, it is used on the instances of class 'Task' which is a subclass of class 'TaskBase'





=== Executing tasks only when something changes

The direct instances of TaskBase are quite limited and do not track the changes to the source files. The class 'Task' provides the necessary features for the most common builds in which source files are used to produce target files. The idea is to create a unique signature for tasks, and to represent the dependencies on files or other tasks by including them in the signature. A hashing function is used for computing the signature, by default it is md5.

The following diagram illustrates the task processing including the signature, it is only valid for Task instance (not TaskBase instances):

image::task_signature{PIC}["Signatures"{backend@docbook:,width=320:},align="center"]

The signature computation uses the following data:

. explicit dependencies: input files and dependencies set explicitly using task.deps_man or bld.depends_on
. implicit dependencies: dependencies searched by the task itself (like source files included from other source files).
. parameters: compilation flags and command-line parameters.

Here is an example illustrating the different kinds of dependencies:

[source,python]
---------------
from waflib import Task
class task_demo(Task.Task):
	vars = ['CXXFLAGS', 'LINKFLAGS'] <1>
	def scan(self): <2>
		return [[self.inputs[0].parent.find_resource('.svn/entries')], []]

task = task_demo()
task.inputs = [bld.path.find_resource('test.cxx')] <3>
task.deps_man = [bld.path.find_resource('wscript')] <4>

bld.add_manual_dependency('main.c', 'an arbitrary string value') <5>
bld.add_manual_dependency(
		bld.path.find_or_declare('test_c_program'),
		bld.path.find_resource('bbb')) <6>
---------------

<1> Environment variable dependencies (compilation flags)
<2> Implicit dependencies: a method returns a list containing the list of additional nodes to take into account, and the list of the files that could not be found (cache)
<3> Explicit dependencies as input files (nodes)
<4> Explicit dependencies as manual dependencies
<5> Manual dependencies on source files, the second parameter can be a string, a node object or a function returning a string
<6> Manual dependencies with nodes, the first node represents a target (which may or may not exist in the build), and the second parameter represents a file in the source directory.

