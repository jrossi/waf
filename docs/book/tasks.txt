
== Task processing

This chapter provides a description of the task classes which are used during the build phase.

=== Task execution

==== Main actors

The build context is only used to create the tasks and to return lists of tasks that may be executed in parallel. The scheduling is delegated to a task producer which lets task consumers to execute the tasks. The task producer keeps a record of the build state such as the amount of tasks processed or the errors.

image::tasks_actors{PIC}["Actors processing the tasks"{backend@docbook:,width=150:},align="center"]

// To reduce the build time, it is interesting to take advantage of the hardware (multiple cpu cores) or of the environment (distributed builds).
The amount of consumers is determined from the number of processors, or may be set manually by using the '-j' option:

[source,shishell]
------------------
$ waf -j3
------------------

==== Build groups

The task producer iterates over lists of tasks returned by the build context. Although the tasks from a list may be executed in parallel by the consumer threads, all the tasks from one list must be consumed before processing another list of tasks. The build ends when there are no more tasks to process.

These lists of tasks are called _build groups_ and may be accessed from the build scripts. Let's demonstrate this behaviour on an example:

// tasks_groups
[source,python]
---------------
def build(ctx):
    for i in range(8):
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_a_%d' % i,
            color='YELLOW', name='tasks a')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_a_%d' % i, target='wscript_b_%d' % i,
            color='GREEN', name='tasks b')
    for i in range(8)
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_c_%d' % i,
            color='BLUE', name='tasks c')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_c_%d' % i, target='wscript_d_%d' % i,
            color='PINK', name='tasks d')
---------------

Each green task must be executed after one yellow task and each pink task must be executed after one blue task. Because there is only one group by default, the parallel execution will be similar to the following:

image::tasks_nogroup{PIC}["One build group"{backend@docbook:,width=440:},align="center"]

We will now modify the example to add one more build group.

[source,python]
---------------
def build(ctx):
    for i in range(8):
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_a_%d' % i,
            color='YELLOW', name='tasks a')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_a_%d' % i, target='wscript_b_%d' % i,
            color='GREEN', name='tasks b')
    ctx.add_group()
    for i in range(8):
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_c_%d' % i,
            color='BLUE', name='tasks c')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_c_%d' % i, target='wscript_d_%d' % i,
            color='PINK', name='tasks d')
---------------

Now a separator will appear between the group of yellow and green tasks and the group of blue and violet taks:

image::tasks_twogroups{PIC}["Two build groups"{backend@docbook:,width=440:},align="center"]

The tasks and tasks generator are added implicitely to the current group. By giving a name to the groups, it is easy to control what goes where:

// tasks_groups2
[source,python]
---------------
def build(ctx):

    ctx.add_group('group1')
    ctx.add_group('group2')

    for i in range(8):
        ctx.set_group('group1')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_a_%d' % i,
            color='YELLOW', name='tasks a')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_a_%d' % i, target='wscript_b_%d' % i,
            color='GREEN', name='tasks b')

        ctx.set_group('group2')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript', target='wscript_c_%d' % i,
            color='BLUE', name='tasks c')
        ctx(rule='cp ${SRC} ${TGT}', source='wscript_c_%d' % i, target='wscript_d_%d' % i,
            color='PINK', name='tasks d')
---------------

NOTE: Build groups prevent task parallelization and may cause longer build times.

==== The Producer-consumer system

In most python interpreters, a global interpreter lock prevents parallelization by more than one cpu core at a time. Therefore, it makes sense to restrict the task scheduling on a single task producer, and to let the threads access only the task execution.

The following illustrates the relationship between the task producers and consumers as performed during the build:

image::prodcons{PIC}["Parallel execution"{backend@docbook:,width=470:},align="center"]

==== Task states and status

A state is a assigned to the each task (_task.hasrun = state_) to keep track of the execution. The possible values are the following:

[options="header", cols="1,1,6"]
|=================
|State    | Numeric value | Description
|NOT_RUN  | 0 | The task has not been processed yet
|MISSING  | 1 | The task outputs are missing
|CRASHED  | 2 | The task method 'run' returned a non-0 value
|EXCEPTION| 3 | An exception occured in the Task method 'run'
|SKIPPED  | 8 | The task was skipped (it was up-to-date)
|SUCCESS  | 9 | The execution was successful
|=================

To decide to execute a task or not, the producer uses the value returned by the task method 'runnable_status'. The possible return values are the following:

[options="header", cols="1,6"]
|=================
|Code    | Description
| ASK_LATER | The task may depend on other tasks which have not finished to run (not ready)
| SKIP_ME   | The task does not have to be executed, it is up-to-date
| RUN_ME    | The task is ready to be executed
|=================

The following diagram represents the main task methods:

image::task_run{PIC}["Task states"{backend@docbook:,width=250:},align="center"]

=== Build order constraints

==== The method set_run_after

The method _set_run_after_ is used to declare ordering constraints between tasks:

[source,python]
---------------
task1.set_run_after(task2)
---------------

The tasks to wait for are stored in the attribute _run_after_. They are used by the method _runnable_status_ to yield the status 'ASK_LATER' when a task has not run yet. This is merely for the build order and not for forcing a rebuild if one of the previous tasks is executed.

==== Computed constraints

===== Attribute after/before

The attributes _before_ and _after_ are used to declare ordering constraints between tasks:

[source,python]
---------------
from waflib import Task
class task_test_a(Task.TaskBase):
    before = 'task_test_b'
class task_test_b(Task.TaskBase):
    after = 'task_test_a'
---------------

===== ext_in/ext_out

Another way to declare precedence constraints is to declare a file extension production, for example:

[source,python]
---------------
from waflib import Task
class task_test_a(Task.TaskBase):
    ext_in = '.c'
class task_test_b(Task.TaskBase):
    ext_out = '.c'
---------------

The 'extensions' ext_in and ext_out have to match to add a valid precedence constraint, but they are only symbols in this context. They do not mean the tasks actually have to produce files of that type.

===== files inputs/outputs

Before feeding the tasks to the producer-consumer system, a constraint extraction is performed on the tasks having input and output files. The attributes _run_after_ are initialized with the tasks to wait for.

==== Weak order constraints

Tasks that are known to take a lot of time may be launched first to improve the build times. The general problem of finding an optimal order for launching tasks in parallel and with constraints is called http://en.wikipedia.org/wiki/Job-shop_problem[Job Shop]. In practice this problem can often be reduced to a critical path problem (approximation).

The following pictures illustrate the difference in scheduling a build with different independent tasks, in which a slow task is clearly identified, and launched first:

[source,python]
---------------
def build(ctx):
	for x in range(5):
		ctx(rule='sleep 1', color='GREEN', name='short task')
	ctx(rule='sleep 5', color='RED', name='long task')
---------------

image::tasks_nosort{PIC}["No particular order"{backend@docbook:,width=440:},align="center"]

A function is used to reorder the tasks from a group before they are passed to the producer. We will replace it to reorder the long task in first position:

// tasks_weak
[source,python]
---------------
old = Task.set_file_constraints
def meth(lst):
	lst.sort() <1>
	old(lst) <2>
Task.set_file_constraints = meth <3>
---------------

<1> Set the long task in first position
<1> Execute the original code
<2> Replace the method

Here is a representation of the effect:

image::tasks_sort{PIC}["Slowest task first"{backend@docbook:,width=440:},align="center"]

=== Dependencies

==== Task signatures

The direct instances of 'waflib.Task.TaskBase' are very limited and cannot be used to track file changes. The subclass 'waflib.Task.Task' provides the necessary features for the most common builds in which source files are used to produce target files.

The dependency tracking is based on the use of hashes of the dependencies called *task signatures*. The signature is computed from various dependencies source, such as input files and configuration set variables.

The following diagram illustrates the task processing for 'waflib.Task.Task' instance:

image::task_signature{PIC}["Signatures"{backend@docbook:,width=280:},align="center"]

The signature computation uses the following data:

. explicit dependencies: input files and dependencies set explicitly using task.deps_man or bld.depends_on
. implicit dependencies: dependencies searched by the task itself (like source files included from other source files).
. parameters: compilation flags and command-line parameters.

Here is an example illustrating the different kinds of dependencies:

[source,python]
---------------
from waflib import Task
class task_demo(Task.Task):
    vars = ['CXXFLAGS', 'LINKFLAGS'] <1>
    def scan(self): <2>
        return [[self.inputs[0].parent.find_resource('.svn/entries')], []]

task = task_demo()
task.inputs = [bld.path.find_resource('test.cxx')] <3>
task.deps_man = [bld.path.find_resource('wscript')] <4>

bld.add_manual_dependency('main.c', 'an arbitrary string value') <5>
bld.add_manual_dependency(
        bld.path.find_or_declare('test_c_program'),
        bld.path.find_resource('bbb')) <6>
---------------

<1> Environment variable dependencies (compilation flags)
<2> Implicit dependencies: a method returns a list containing the list of additional nodes to take into account, and the list of the files that could not be found (cache)
<3> Explicit dependencies as input files (nodes)
<4> Explicit dependencies as manual dependencies
<5> Manual dependencies on source files, the second parameter can be a string, a node object or a function returning a string
<6> Manual dependencies with nodes, the first node represents a target (which may or may not exist in the build), and the second parameter represents a file in the source directory.

==== Explicit dependencies

TODO

==== Implicit dependencies and scanners

TODO

==== Variables

TODO


////
=== Task execution order

Running tasks in parallel is a simple problem, but in practice it is more complicated:
. Dependencies can be discovered during the build (dynamic task creation)
. New ordering constraints can be discovered after files are compiled
. The amount of tasks and ordering constraints (graph size) can be huge and performance may be a problem

To make the problem more simple, it is divided by the different concerns, and the ordering constraints can be given on three different levels:

. groups of tasks may run only after another group of tasks has finished to run, this represents a strict sequential order between groups of tasks, for example a compiler is produced and used to compile the tasks in the next group
. task types to indicate the instance will run after other task type instances, for example linking object files may only occur after compiling the source files
. specific constraints for task instances that can only run after a few other task instances

unlike the previous constraints, it is used on the instances of class 'Task' which is a subclass of class 'TaskBase'
////


