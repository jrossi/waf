== Advanced scenarios

This chapter demonstrates a few examples of the waf library for more complicated and less common scenarios.

=== Building the compiler first

The example below demonstrates how to build a compiler which is used for building the remaining targets. The requirements are the following:

. Create the compiler and all its intermediate tasks
. Re-use the compiler in a second build step
. The compiler will transform '.src' files into '.cpp' files, which will be processed too
. Call the compiler again if it was rebuilt (add the dependency on the compiler)

The first thing to do is to write the expected user script:

// scenarios_compiler
[source,python]
---------------
top = '.'
out = 'build'

def configure(ctx):
	ctx.check_tool('g++')
	ctx.check_tool('src2cpp', tooldir='.')

def build(ctx):
	ctx.program( <1>
		source = 'comp.cpp',
		target = 'comp')

	ctx.add_group() <2>

	ctx.program(
		source = 'main.cpp a.src', <3>
		target = 'foo')
---------------

<1> Build the compiler first, it will result in a binary named _comp_
<2> Add a new build group to make certain the compiler is complete before processing the next tasks
<3> The file 'a.src' is to be transformed by 'comp' into 'a.cpp'

The code for the _src → cpp_ conversion will be the following:

[source,python]
---------------
from waflib.Task import Task
class src2cpp(Task): <1>
	run_str = '${SRC[0].abspath()} ${SRC[1].abspath()} ${TGT}'
	color   = 'PINK'

from waflib.TaskGen import extension

@extension('.src')
def process_src(self, node): <2>
	tg = self.bld.get_tgen_by_name('comp') <3>
	comp = tg.link_task.outputs[0]
	tsk = self.create_task('src2cpp', [comp, node], node.change_ext('.cpp')) <4>
	self.source.extend(tsk.outputs) <5>
---------------

<1> Declare a new task class for processing the source file by our compiler
<2> Files of extension '.src' are to be processed by this method
<3> Obtain a reference on the task generator producing the compiler
<4> Create the task 'src → cpp', the compiler being as used as the first source file
<5> Add the generated 'cpp' file to be processed too

The compilation results will be the following:

[source,shishell]
---------------
$ waf distclean configure build -v
'distclean' finished successfully (0.006s)
Setting top to                           : /tmp/scenarios_compiler
Setting out to                           : /tmp/scenarios_compiler/build
Checking for program g++,c++             : /usr/bin/g++
Checking for program ar                  : /usr/bin/ar
'configure' finished successfully (0.118s)
Waf: Entering directory `/tmp/scenarios_compiler/build'
[1/5] cxx: comp.cpp -> build/comp.cpp.0.o
10:21:14 runner ['/usr/bin/g++', '../comp.cpp', '-c', '-o', 'comp.cpp.0.o']
[2/5] cxxprogram: build/comp.cpp.0.o -> build/comp <1>
10:21:14 runner ['/usr/bin/g++', 'comp.cpp.0.o', '-o', '/tmp/scenarios_compiler/build/comp']
[3/5] cxx: main.cpp -> build/main.cpp.1.o
10:21:15 runner ['/usr/bin/g++', '../main.cpp', '-c', '-o', 'main.cpp.1.o']
[4/5] src2cpp: a.src -> build/a.cpp
10:21:15 runner ['/tmp/scenarios_compiler/build/comp', '../a.src', 'a.cpp'] <2>
[5/5] cxxprogram: build/main.cpp.1.o -> build/foo <3>
10:21:15 runner ['/usr/bin/g++', 'main.cpp.1.o', '-o', 'foo']
Waf: Leaving directory `/tmp/scenarios_compiler/build'
'build' finished successfully (1.009s)
---------------

<1> Creation of the 'comp' program
<2> Use the compiler to generate 'a.cpp'
<3> Compile and link 'a.cpp' and 'main.cpp' into the program 'foo'

NOTE: When `waf --targets=foo' is called, the task generator `comp' will create its tasks too (task generators from previous groups are processed).

=== Mixing extensions and c/c++ features

==== Files processed by a single task generator

Now let's illustrate the @extension decorator on idl file processing. Files with .idl extension are processed to produce .c and .h files (`foo.idl` → `foo.c` + `foo.h`). The .c files must be compiled after being generated.

First, here is the declaration expected in user scripts:

[source,python]
---------------
top = '.'
out = 'build'

def configure(conf):
	conf.check_tool('g++')

def build(bld):
	bld(
		features = 'cxx cprogram',
		source   = 'foo.idl main.cpp',
		target   = 'myapp'
		)
---------------

The file 'foo.idl' is listed as a source. It will be processed to 'foo.cpp' and compiled and linked with 'main.cpp'

Here is the code to support this scenario:

[source,python]
---------------
from waflib import Task
from waflib.TaskGen import extension

Task.simple_task_type('idl', 'cp ${SRC} ${TGT}', color='BLUE', before='cxx') <1>

@extension('.idl')
def process_idl(self, node):
	cc_node = node.change_ext('.cpp')
	self.create_task('idl', [node], [cc_node]) <2>
	self.source.append(cc_node) <3>
---------------

<1> The ext_out symbol is to force the idl execution before any c++ file is processed. In practice the rule to use would be like `omniidl -bcxx ${SRC} -C${TGT}`
<2> Create the task from the '.idl' extension. If the task produces other files (headers, ...), more nodes should be added along with 'cc_node'.
<3> Reinject the c++ node to the list of nodes to process

The compilation results will be the following:

[source,shishell]
---------------
$ waf distclean configure build
'distclean' finished successfully (0.002s)
Checking for program g++,c++             : ok /usr/bin/g++
Checking for program cpp                 : ok /usr/bin/cpp
Checking for program ar                  : ok /usr/bin/ar
Checking for program ranlib              : ok /usr/bin/ranlib
'configure' finished successfully (0.033s)
Waf: Entering directory `/tmp/idl/build'
[1/4] idl: foo.idl -> build/foo.cc
[2/4] cxx: build/foo.cc -> build/foo_1.o
[3/4] cxx: main.cpp -> build/main_1.o
[4/4] cxx_link: build/main_1.o build/foo_1.o -> build/myapp
Waf: Leaving directory `/tmp/idl/build'
'build' finished successfully (0.119s)
---------------

NOTE: The drawback of this declaration is that the source files produced by the idl transformation are used by only one task generator.

==== Resources shared by several task generators

Now suppose that the idl processing outputs will be shared by several task generators. We will first start by writing the expected user script:

[source,python]
---------------
top = '.'
out = 'out'

def configure(ctx):
	ctx.check_tool('g++')

def build(bld):
	bld( <1>
		source     = 'notify.idl',
		name       = 'idl_gen')

	bld( <2>
		features   = 'cxx cprogram',
		source     = 'main.cpp',
		target     = 'testprog',
		add_source = 'idl_gen') <3>
---------------

<1> Process an idl file in a first task generator. Name this task generator 'idl_gen'
<2> Somewhere else (maybe in another script), another task generator will use the source generated by the idl processing
<3> Reference the idl processing task generator by the name 'idl_gen'. This declaration is is similar to 'add_objects'

The code to support this scenario will be the following:

[source,python]
---------------
from waflib import Task
from waflib TaskGen import feature, before, extension
Task.simple_task_type('idl', 'cp ${SRC} ${TGT}', before='cxx') <1>

@extension('.idl')
def compile_idl(self, node): <2>
	c_node = node.change_ext('.cpp')
	self.create_task('idl', node, c_node)
	self.more_source = [c_node] <3>

@feature('*')
@before('apply_core')
def process_add_source(self): <4>
	if not getattr(self, 'add_source', None):
		return

	for x in self.to_list(self.add_source): <5>
		y = self.bld.name_to_obj(x, self.env) <6>
		y.post() <7>

		if getattr(y, 'more_source', None):
			self.source.extend(y.more_source) <8>
---------------

<1> The idl processing must be performed before any c++ task is executed
<2> This is the standard way to process a file by extension
<3> Bind the output nodes to a new task generator attribute 'more_source'
<4> A new task generator method is added to process the attribute 'add_source'
<5> Process each reference in 'add_source'
<6> Get the task generator from the reference, and for the current variant. In the example above this is the name 'idl_gen'
<7> Force the task generator we depend on to create its tasks
<8> Add the sources from the other task generator to the current list of source

The task execution output will be very similar to the output from the first example:

[source,shishell]
---------------
$ waf distclean configure build
'distclean' finished successfully (0.001s)
Checking for program g++,c++             : ok /usr/bin/g++
Checking for program cpp                 : ok /usr/bin/cpp
Checking for program ar                  : ok /usr/bin/ar
Checking for program ranlib              : ok /usr/bin/ranlib
'configure' finished successfully (0.041s)
Waf: Entering directory `/home/waf/Descargas/blah/out'
[1/4] idl: notify.idl -> out/notify.cpp
[2/4] cxx: out/notify.cpp -> out/notify_2.o
[3/4] cxx: main.cpp -> out/main_2.o
[4/4] cxx_link: out/notify_2.o out/main_2.o -> out/testprog
Waf: Leaving directory `/home/waf/Descargas/blah/out'
'build' finished successfully (0.124s)
---------------

NOTE: This technique is used by the waf library for processing the 'add_objects' attribute.

=== Inserting special include flags

A scenario that appears from ltimes to times in C/C++ projects is the need to insert specific flags before others, regardless of how flags are usually processed. We will now consider the following case: execute all c++ compilations with the flag `-I.' in first position (before any other include).

First, a look at the definition of the c++ compilation rule shows that the variable 'INCPATHS' contains the include flags:

[source,python]
---------------
class cxx(Task.Task):
	color   = 'GREEN'
	run_str = '${CXX} ${CXXFLAGS} ${CPPPATH_ST:INCPATHS} ${CXX_SRC_F}${SRC} ${CXX_TGT_F}${TGT}'
	vars    = ['CXXDEPS']
	ext_in  = ['.h']
	scan    = ccroot.scan
---------------

Those include flags are set by the method 'apply_incpaths'. The trick is then to modify 'INCPATHS' after that method has been executed:

// scenarios_incflags
[source,python]
---------------
top = '.'
out = 'build'

def configure(conf):
	conf.check_tool('g++')

def build(bld):
	bld.program(features='cxx cxxprogram', source='main.cpp', target='test')

from waflib.TaskGen import after, feature

@feature('cxx')
@after('apply_incpaths')
def insert_blddir(self):
	self.env.prepend_value('INCPATHS', '.')
---------------

A related case is how to add the top-level directory containing a configuration header:

[source,python]
---------------
@feature('cxx')
@after('apply_incpaths', 'insert_blddir')
def insert_srcdir(self):
	path = self.bld.srcnode.abspath()
	self.env.prepend_value('INCPATHS', path)
---------------

////
=== Simple file transformations

The Waf tool 'misc' contains various routines to ease file manipulations such as substituting parameters or executing custom compilers. The objective of this section is to illustrate the principles of the current apis.

The following example illustrates how to produce a pkg-config file from a template:

[source,python]
---------------
top = '.'
out = 'build'

def configure(conf):
	conf.check_tool('misc')

def build(bld):
	obj = bld(
		features = 'subst',
		source   = 'test.pc.in',
		target   = 'test.pc')
	obj.dict     = {'LIBS': '-lm', 'CFLAGS': '-Wall', 'VERSION': '1.0'}
---------------

Any kind of map will work for 'obj.dict', for example env.get_merged_dict(). The variables must be declared in the template file by enclosing the names between '@ characters' (m4 syntax):

[source,shishell]
---------------
Name: test
Description: @CFLAGS@
Version: @VERSION@
Libs: -L${libdir} @LIBS@
Cflags: -I${includedir} @CFLAGS@
---------------

The default substitution function may be replaced by changing the attribute 'func' of the task generator.

////

=== Arbitrary configuration files

A file is copied into the build directory before the build starts. The build may use this file for building other targets.

// scenarios_impfile
[source,python]
---------------
cfg_file = 'somedir/foo.txt'

def configure(conf):

	orig = conf.root.find_node('/etc/fstab')
	txt = orig.read() <1>

	dest = conf.bldnode.make_node(cfg_file)
	dest.parent.mkdir()
	dest.write(txt) <2>

	conf.env.append_value('cfg_files', cfg_file) <3>

def build(ctx):
	ctx(rule='cp ${SRC} ${TGT}', source=cfg_file, target='bar.txt')
---------------

<1> Read the file '/etc/fstab'
<2> Create a new file in the build directory
<3> Mark the output as a configuration file so it can be used during the build

The execution output will be the following:

[source,shishell]
---------------
$ waf configure build
Setting top to     : /tmp/scenarios_impfile
Setting out to     : /tmp/scenarios_impfile/build
'configure' finished successfully (0.003s)
Waf: Entering directory `/tmp/scenarios_impfile/build'
[1/1] bar.txt: build/somedir/foo.txt -> build/bar.txt
Waf: Leaving directory `/tmp/scenarios_impfile/build'
'build' finished successfully (0.008s)

$ tree
.
|-- build
|   |-- bar.txt
|   |-- c4che
|   |   |-- build.config.py
|   |   `-- default.cache.py
|   |-- config.log
|   `-- somedir
|       `-- foo.txt
`-- wscript
---------------

=== Force the compilation of a particular task

In some applications, it may be interesting to keep track of the date and time of the last build. In C this may be done by using the macros `__DATE__' and `__TIME__', for example, the following +about.c+ file will contain:

[source,c]
---------------
void ping() {
	printf("Project compiled: %s %s\n", __DATE__, __TIME__);
}
---------------

The files are only compiled when they change though, so it is necessary to find a way to force the recompilation of a the file containing the macros. To sum up, the compilation should be performed whenever:

. One of the c files of the project is compiled
. The link flags for any task change
. The link task including the object for our macro is removed

To illustrate this behaviour, we will now set up a project will use various c files:

// scenarios_end
[source,python]
---------------
def options(opt):
	opt.tool_options('compiler_c')

def configure(conf):
	conf.check_tool('compiler_c')

def build(bld):
	bld.program(
		source   = 'main.c about.c',
		target   = 'app',
		includes = '.',
		use      = 'my_static_lib')

	bld.stlib(
		source   = 'test_staticlib.c',
		target   = 'my_static_lib')
---------------

The main file will just call the function _ping_ defined +about.c+ to display the date and time:

[source,c]
---------------
#include "a.h"

int main() {
	ping();
	return 0;
}
---------------

The task method _runnable_status_ must be overridden to take into account the dependencies:

[source,python]
---------------
import os
from waflib import Task
def runnable_status(self):
	if self.inputs[0].name == 'about.c': <1>
		h = 0 <2>
		for g in self.generator.bld.groups:
			for tg in g:
				if isinstance(tg, TaskBase):
					continue <3>

				h = hash((self.generator.bld.hash_env_vars(self.generator.env, ['LINKFLAGS']), h))
				for tsk in getattr(tg, 'compiled_tasks', []): # all .c or .cpp compilations
					if id(tsk) == id(self):
						continue
					if not tsk.hasrun:
						return Task.ASK_LATER
					h = hash((tsk.signature(), h)) <4>
		self.env.CCDEPS = h

		try:
			os.stat(self.generator.link_task.outputs[0].abspath()) <5>
		except:
			return Task.RUN_ME

	return Task.Task.runnable_status(self) <6>

from waflib.Tools.c import c <7>
c.runnable_status = runnable_status
---------------

<1> If the task processes +about.c+
<2> Define a hash value that the task will depend on (CCDEPS)
<3> Iterate over all task generators of the project
<4> Hash the link flags and the signatures of all other compilation tasks
<5> Make sure to execute the task if it was never executed before
<6> Normal behaviour
<7> Modify the 'c' task class

The execution will produce the following output:

[source,shishell]
---------------
$ waf
Waf: Entering directory `/tmp/scenarios_end/build'
[2/5] c: test_staticlib.c -> build/test_staticlib.c.1.o
[3/5] cstlib: build/test_staticlib.c.1.o -> build/libmy_static_lib.a
[4/5] c: about.c -> build/about.c.0.o
[5/5] cprogram: build/main.c.0.o build/about.c.0.o -> build/app
Waf: Leaving directory `/tmp/scenarios_end/build' <1>
'build' finished successfully (0.088s)

$ ./build/app
Project compiled: Jul 25 2010 14:05:30

$ echo " " >> main.c <2>

$ waf
Waf: Entering directory `/tmp/scenarios_end/build'
[1/5] c: main.c -> build/main.c.0.o
[4/5] c: about.c -> build/about.c.0.o <3>
[5/5] cprogram: build/main.c.0.o build/about.c.0.o -> build/app
Waf: Leaving directory `/tmp/scenarios_end/build'
'build' finished successfully (0.101s)

$ ./build/app
Project compiled: Jul 25 2010 14:05:49
---------------

<1> All files are compiled on the first build
<2> The file +main.c+ is modified
<3> The build generates +about.c+ again to update the build time string

=== A compiler producing source files with names unknown in advance

The requirements for this problem are the following:

. A compiler *creates source files* (one .src file -> several .c files)
. The source file names to create are *known only when the compiler is executed*
. The compiler is slow so it should run *only when absolutely necessary*
. Other tasks will *depend on the generated files* (compile and link the .c files into a program)

To do this, the information on the source files must be shared between the build executions.

// scenarios_unknown
[source,python]
---------------
top = '.'
out = 'build'

def configure(conf):
	conf.check_tool('gcc')
	conf.check_tool('mytool', tooldir='.')

def build(bld):
	bld.env.COMP = bld.path.find_resource('evil_comp.py').abspath() <1>
	bld.stlib(source='x.c foo.src', target='astaticlib') <2>
---------------

<1> Compiler path
<2> An example, having a _.src_ file

The contents of _mytool_ will be the following

[source,python]
---------------
import os
from waflib import Task, Utils, Context
from waflib.Utils import subprocess
from waflib.TaskGen import extension

@extension('.src')
def process_shpip(self, node): <1>
	self.create_task('src2c', node)

class src2c(Task.Task):
	color = 'PINK'
	quiet = 1 <2>
	ext_out = ['.h'] <3>

	def run(self):
		cmd = '%s %s' % (self.env.COMP, self.inputs[0].abspath())
		cwd = self.inputs[0].parent.get_bld().abspath()
		out = self.generator.bld.cmd_and_log(cmd, cwd=cwd, quiet=Context.STDOUT) <4>

		out = Utils.to_list(out)
		self.outputs = [self.generator.path.find_or_declare(x) for x in out]
		self.generator.bld.raw_deps[self.uid()] = [self.signature()] + self.outputs <5>
		self.add_c_tasks(self.outputs) <6>

	def add_c_tasks(self, lst):
		self.more_tasks = []
		for node in lst:
			if node.name.endswith('.h'):
				continue
			tsk = self.generator.create_compiled_task('c', node)
			self.more_tasks.append(tsk) <7>

			tsk.env.append_value('INCPATHS', [node.parent.abspath()])

			if getattr(self.generator, 'link_task', None): <8>
				self.generator.link_task.set_run_after(tsk)
				self.generator.link_task.inputs.append(tsk.outputs[0])

	def runnable_status(self):
		ret = super(src2c, self).runnable_status()
		if ret == Task.SKIP_ME:

			lst = self.generator.bld.raw_deps[self.uid()]
			if lst[0] != self.signature():
				return Task.RUN_ME

			nodes = lst[1:]
			for x in nodes:
				try:
					os.stat(x.abspath())
				except:
					return Task.RUN_ME

			nodes = lst[1:]
			self.set_outputs(nodes)
			self.add_c_tasks(nodes) <9>

		return ret
---------------

<1> The processing will be delegated to the task
<2> Disable the warnings raised when a task has no outputs
<3> Make certain the processing will be executed before any task using _.h_ files
<4> When the task is executed, collect the process stdout which contains the generated file names
<5> Store the output file nodes in a persistent cache
<6> Create the tasks to compile the outputs
<7> The c tasks will be processed after the current task is done. This does not mean that the c tasks will always be executed.
<8> If the task generator of the _src_ file has a link task, set the build order
<9> When this task can be skipped, force the dynamic c task creation

The output will be the following:

[source,shishell]
---------------
$ waf distclean configure build build
'distclean' finished successfully (0.006s)
Setting top to  : /tmp/scenarios_unknown
Setting out to  : /tmp/scenarios_unknown/build
Checking for program gcc,cc              : /usr/bin/gcc
Checking for program ar                  : /usr/bin/ar
'configure' finished successfully (0.115s)
Waf: Entering directory `/tmp/scenarios_unknown/build'
[1/3] src2c: foo.src
[2/5] c: build/shpip/a12.c -> build/shpip/a12.c.0.o
[3/5] c: build/shpop/a13.c -> build/shpop/a13.c.0.o
[4/5] c: x.c -> build/x.c.0.o
[5/5] cstlib: build/x.c.0.o build/shpip/a12.c.0.o build/shpop/a13.c.0.o -> build/libastaticlib.a
Waf: Leaving directory `/tmp/scenarios_unknown/build'
'build' finished successfully (0.188s)
Waf: Entering directory `/tmp/scenarios_unknown/build'
Waf: Leaving directory `/tmp/scenarios_unknown/build'
'build' finished successfully (0.013s)
---------------

